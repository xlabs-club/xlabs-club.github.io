<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>G1 on XLabs</title><link>https://www.xlabs.club/tags/g1/</link><description>Recent content in G1 on XLabs</description><generator>Hugo</generator><language>zh</language><copyright>Copyright (c) 2020-2025 XLabs Club</copyright><lastBuildDate>Sun, 28 Dec 2025 11:59:43 +0800</lastBuildDate><atom:link href="https://www.xlabs.club/tags/g1/index.xml" rel="self" type="application/rss+xml"/><item><title>K8S Pod 容器内 Java 进程内存分析，内存虚高以及容器 OOM 或 Jave OOM 问题定位</title><link>https://www.xlabs.club/blog/java-memory/</link><pubDate>Sat, 07 Jan 2023 10:54:37 +0800</pubDate><guid>https://www.xlabs.club/blog/java-memory/</guid><description>&lt;p&gt;故事背景：&lt;/p&gt;
&lt;p&gt;一个 K8S Pod，里面只有一个 Java 进程，K8S request 和 limit memory 都是 2G，Java 进程核心参数包括：&lt;code&gt;-XX:+UseZGC -Xmx1024m -Xms768m&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;服务启动一段时间后，查看 Grafana 监控数据，Pod 内存使用量约 1.5G，JVM 内存使用量约 500M，通过 jvm dump 分析没有任何大对象，运行三五天后出现 K8S Container OOM。&lt;/p&gt;
&lt;p&gt;首先区分下 Container OOM 和 Jvm OOM，Container OOM 是 Pod 内进程申请内存大约 K8S Limit 所致。&lt;/p&gt;
&lt;p&gt;问题来了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Pod 2G 内存，JVM 设置了 &lt;code&gt;Xmx 1G&lt;/code&gt;，已经预留了 1G 内存，为什么还会 Container OOM，这预留的 1G 内存被谁吃了。&lt;/li&gt;
&lt;li&gt;正常情况下（无 Container OOM），Grafana 看到的监控数据，Pod 内存使用量 1.5G， JVM 内存使用量 500M，差别为什么这么大。&lt;/li&gt;
&lt;li&gt;Pod 内存使用量为什么超过 Xmx 限制。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Grafana 监控图。&lt;/p&gt;
&lt;p&gt;&lt;a href="./grafana-pod-jvm.png"&gt;

&lt;img
 src="https://www.xlabs.club/blog/java-memory/grafana-pod-jvm_hu_f3e003bf88afca3a.webp"
 width="1920"
 height="3600"
 decoding="async"
 fetchpriority="auto"
 loading="lazy"
 alt="Grafana 监控图"
 id="h-rh-i-0"
&gt;&lt;/a&gt;
&lt;/p&gt;</description></item></channel></rss>